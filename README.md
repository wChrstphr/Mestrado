# Pipeline de Coleta de Dados para Machine Learning

Sistema para coleta e processamento de dados processuais do TJCE.

## ğŸ¯ InÃ­cio RÃ¡pido

### Passo 1: Coleta Inicial via API

Execute o notebook `notebooks/tjce.ipynb` para:
- Coletar dados da API do TJCE
- Filtrar e balancear processos por decisÃ£o
- Gerar arquivos iniciais em `data/`

**O notebook contÃ©m instruÃ§Ãµes detalhadas para os prÃ³ximos passos.**

### Passo 2: Pipeline de Dados Completo

ApÃ³s executar o notebook, colete os dados adicionais por webscrapping:

```bash
python coletar_dados_ml.py
```

Este comando executa automaticamente:
1. Web Scraping (juÃ­zes e requerentes)
2. InferÃªncia de Sexo
3. GeraÃ§Ã£o de Features (29 features para ML)

## ğŸ“ Estrutura do Projeto

```
Mestrado/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ tjce.ipynb               # 1. INÃCIO: Coleta da API e filtros
â”œâ”€â”€ coletar_dados_ml.py          # 2.  Executa pipeline de coleta por meio dos scripts
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraper_tjce.py          # Web Scraping
â”‚   â”œâ”€â”€ inferir_sexo.py          # InferÃªncia de Sexo
â”‚   â””â”€â”€ gerar_features.py        # GeraÃ§Ã£o de Features
â”œâ”€â”€ data/                        # Arquivos de entrada/saÃ­da
â””â”€â”€ requirements.txt
```

## ğŸš€ ExecuÃ§Ã£o do Pipeline

### Pipeline Completo

```bash
python coletar_dados_ml.py
```

### Etapas Individuais

```bash
# Apenas scraping
python coletar_dados_ml.py --etapa scraping

# Apenas inferÃªncia de sexo
python coletar_dados_ml.py --etapa inferir_sexo

# Apenas geraÃ§Ã£o de features
python coletar_dados_ml.py --etapa features
```

## ğŸ“Š Sobre as Etapas

### 1. Web Scraping
Coleta dados adicionais do site do TJCE (nome do juiz e requerente).

### 2. InferÃªncia de Sexo
Infere sexo a partir dos nomes usando base de dados brasileiros.

### 3. GeraÃ§Ã£o de Features
Gera dataset final com **29 features** para ML.

## âš™ï¸ InstalaÃ§Ã£o

### 1. Criar e ativar ambiente virtual

```bash
# Criar
python -m venv venv

# Ativar (Windows)
.\venv\Scripts\activate
```

### 2. Instalar dependÃªncias

```bash
pip install -r requirements.txt
playwright install chromium
```

## ğŸ“‚ Arquivos Gerados

**ApÃ³s notebook:**
- `data/dados_completos.json`
- `data/numeros_processos.csv`
- `data/decisoes_resumo.csv`

**ApÃ³s pipeline:**
- `data/dados_processos_tjce.csv`
- `data/dados_processos_com_sexo.csv`
- `data/dataset_ml_completo.csv` (29 features)

## ğŸ“– DocumentaÃ§Ã£o Completa

Para detalhes tÃ©cnicos completos sobre as 29 features e funcionamento interno, consulte `docs/README_PIPELINE.md`.

## ğŸ“ LicenÃ§a

Este projeto Ã© parte de dissertaÃ§Ã£o de mestrado de Giovanni Brigido Bezerra Cardoso.

## ğŸ‘¨â€ğŸ’» Autores

Giovanni Brigido Bezerra Cardoso - Mestrado em I.A e CiÃªncia de Dados

Wanjo Christopher Paraizo Escobar - Graduando em Engenharia de Software
